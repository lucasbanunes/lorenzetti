#!/usr/bin/env python3
import argparse
import sys
import os

from pathlib            import Path
from joblib             import Parallel, delayed
from expand_folders     import expand_folders
from GaugiKernel        import LoggingLevel, get_argparser_formatter
from GaugiKernel        import ComponentAccumulator
from RootStreamBuilder  import RootStreamHITReader, recordable
from CaloCellBuilder    import PileupMerge
from RootStreamBuilder  import RootStreamHITMaker

from reco import merge_args, update_args, merge, get_input_output_job_pairs


def parse_args():
    # create the top-level parser
    parser = argparse.ArgumentParser(
        description='',
        formatter_class=get_argparser_formatter(),
        add_help=False)

    parser.add_argument('-i', '--input-file', action='store',
                        dest='input_file', required=False,
                        help="The event HIT input file generated by the"
                        " simu_trf.py stage.")
    parser.add_argument('-o', '--output-file', action='store',
                        dest='output_file', required=False,
                        help="The reconstructed event HIT file merged with pileup.")
    parser.add_argument('-p','--pileup-file', action='store', 
                        dest='pileup_file', required = True,
                        help = "The event HIT file to be merged (pileup).")
    parser.add_argument('--nov', '--number-of-events', action='store',
                        dest='number_of_events', required=False,
                        type=int, default=-1,
                        help="The number of events to apply the"
                        " reconstruction.")
    parser.add_argument('-l', '--output-level', action='store',
                        dest='output_level', required=False,
                        type=str, default='INFO',
                        help="The output level messenger.")
    parser.add_argument('-c', '--command', action='store',
                        dest='command', required=False, default="''",
                        help="The preexec command")
    parser.add_argument('-nt', '--number-of-threads', action='store',
                        dest='number_of_threads', required=False,
                        type=int, default=1,
                        help="The number of threads")
    parser.add_argument('-m','--merge', action='store_true',
                        dest='merge', required=False,
                        help='Merge all files.')
    parser = merge_args(parser)

    return parser


def main(logging_level: str,
         input_file: str | Path,
         output_file: str | Path,
         pileup_file: str | Path,
         command: str,
         number_of_events: int):

    if isinstance(input_file, Path):
        input_file = str(input_file)
    if isinstance(output_file, Path):
        output_file = str(output_file)
    if isinstance(pileup_file, Path):
        pileup_file = str(pileup_file)

    outputLevel = LoggingLevel.toC(logging_level)

    exec(command)

    acc = ComponentAccumulator("ComponentAccumulator", output_file)

    reader = RootStreamHITReader("HITReader", 
                                  InputFile       = input_file,
                                  OutputHitsKey   = recordable("Hits"),
                                  OutputEventKey  = recordable("Events"),
                                  OutputTruthKey  = recordable("Particles"),
                                  OutputSeedsKey  = recordable("Seeds"),
                                  OutputLevel     = outputLevel,
                                )
    reader.merge(acc)

    pileup = PileupMerge( "PileupMerge", 
                          InputFile       = pileup_file,
                          InputHitsKey    = recordable("Hits"),
                          InputEventKey   = recordable("Events"),
                          OutputHitsKey   = "Hits_Merged",
                          OutputEventKey  = "Events_Merged",
                          OutputLevel     = outputLevel
                        )
    acc += pileup

    HIT = RootStreamHITMaker( "RootStreamHITMaker",
                               # input from context
                               InputHitsKey    = "Hits_Merged",
                               InputEventKey   = "Events_Merged",
                               InputTruthKey   = recordable("Particles"),
                               InputSeedsKey   = recordable("Seeds"),
                               # output to file
                               OutputHitsKey   = recordable("Hits"),
                               OutputEventKey  = recordable("Events"),
                               OutputLevel     = outputLevel)
    acc += HIT
    acc.run(number_of_events)



def run(args):

    args.input_file = Path(args.input_file)
    args.pileup_file = Path(args.pileup_file)
    if not args.input_file.exists():
        raise FileNotFoundError(f"Input file {args.input_file} not found.")
    if args.input_file.is_dir():
        args.input_file = expand_folders(os.path.abspath(args.input_file))
    else:
        args.input_file = [args.input_file]

    args.pileup_file = Path(args.pileup_file)
    if not args.pileup_file.exists():
        raise FileNotFoundError(f"Pileup input file {args.pileup_file} not found.")


    pool = Parallel(n_jobs=args.number_of_threads)
    pool(delayed(main)(
            logging_level=args.output_level,
            input_file=input_file,
            output_file=output_file,
            pileup_file=args.pileup_file,
            command=args.command,
            number_of_events=args.number_of_events
    )
        for input_file, output_file in get_input_output_job_pairs(args))
    
    files = [f"{os.getcwd()}/{f}" for _, f in get_input_output_job_pairs(args, force=True)]
    if args.merge:
        merge(args, files)
       

       


if __name__ == "__main__":
    parser=parse_args()
    if len(sys.argv) == 1:
        parser.print_help()
        sys.exit(1)
    args = parser.parse_args()
    args = update_args(args)

    run(args)
